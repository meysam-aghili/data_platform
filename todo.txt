-------KAFKA QA
aya port dakheli expose shode yek image baraye yek containeri ke ba compose file dg vali network yeksan oomade bala baze?
	age are pas chra port metric exporter connect ro map kardi be biron?
chra baazi jaha ye port ro 2bar avordi biron?
artin kafka volumes chra yekie baraye controller ha va broker ha
KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT mishe CONTROLLER:PLAINTEXT ro hazv kard?
chra port internal va external kafka ro keshidi biron
chra port controller kafka ro keshidi biron
kafka-cli be dard mikhore
kafka-rest be dard mikhore
kafdrop ya kafka ui kodomesh?
tedad partition haro chejuri mohasebe mikonid , orders chanta partition dare?
age ye broker fail she replication factor dobare emal mishe? partition ha chi mishn?
reconsilation chie
get sample connector artin
strategy consume haye mokhtalef mesle range ya sticky karbord dare?
acks ro gozashti -1 yani chi age alle ykm tool nmikeshe?
idempotence chie?
az kafka transaction estefade kardi?
data imbalance ro chejuri handle mikonid

-------CLICKHOUSE QA
che datai too click hosue ngeah midarid ? khame orders ya agg data of orders?
ttl table ha mamoln chejuri mizarid? maslan table orders
optimize table final ?
index_granularity option ? index types?
primary key vs order by deatil?
explain indexes=1 ?
Adding a projection to our existing table. what is that?
ALL DDL AND QUERY TIPS
data skipping index?
projection?
az aggmergetree estefade mikonid? ya hamon mergetree mizanid va roosh query agg mizanid
chanta broker node va keeper node darid? chanta sahrd chanta replica darid?


fix create table on cluster bug
setup clickhouse
	https://clickhouse.com/docs/en/use-cases/observability/introduction
add postgres data to clickhouse based on best practices
visual data using grafana, metabase, powerbi, tableau, supercet

add logs to elk stack and visual
add influx for time series data and visual
add minio
add spark

test dagster

ksql
sasl and security







{
  "connector.class": "io.confluent.connect.jdbc.JdbcSinkConnector",
  "tasks.max": "1",
  "topics": "orders",
  "value.converter": "io.confluent.connect.avro.AvroConverter",
  "value.converter.schema.registry.url": "http://schema-registry:8081",
  "value.converter.enhanced.avro.schema.support": true,
  "key.converter": "org.apache.kafka.connect.storage.StringConverter",
  "connection.url": "jdbc:mysql://mysql:3306/test_db",
  "connection.user": "mysql",
  "connection.password": "mysql",
  "transforms": "unwrap",
  "transforms.unwrap.type": "io.debezium.transforms.ExtractNewRecordState",
  "transforms.unwrap.drop.tombstones": "false",

  "table.name.format": "orders",
  "pk.mode": "record_value",
  "pk.fields": "id",
  "insert.mode": "upsert",
 
  "auto.create": "true",
  "errors.tolerance": "all",
  "errors.log.enable": "true",
  "errors.log.include.messages": "true"
}

