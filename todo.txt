-------KAFKA QA
ksql image server db kodom?
get sample connector artin
tell artin
    docker config
    replicated-job

-------CLICKHOUSE QA
che datai too click hosue ngeah midarid ? khame orders ya agg data of orders?
ttl table ha mamoln chejuri mizarid? maslan table orders
az aggmergetree estefade mikonid? ya hamon mergetree mizanid va roosh query agg mizanid
chanta broker node va keeper node darid? chanta sahrd chanta replica darid?
az kafka engine ya sink connector?

-------INFLUXDB QA
vase config clusteresh bayad license dasht?
  https://github.com/chengshiwen/influxdb-cluster
  https://github.com/Diver2daze/influxdb_cluster/blob/enterprise-images/docker-compose.yml

-------SPARK QA
vaghti ye read va transformation dsitributed anjam mishe va mikhaym write konim aya har worker joda write mikone ya ghablesh collect mikone?
SPARKDAEMON_MEMORY chie ? nist too docs
chera spark logs ro volume kardi?
chanta master nmizaran?
chra az ADD bejaye COPY?
BIHUB_REPO_ID chie too jupyterhub compose ?
proxy jupyterhub vase chi gozashti?
tell artin 
  about hostname jupyterhub and proxy
  idle remover
fargh spark context va session
--------------------------------------
connect to spark

add spark
apache flink
add logs to elk stack and visual
splunk
add minio
network docker swarm problem for kafka
metabase taha
write kafka to influxdb sink connector
hadoop
test dagster
ksql
nginx haproxy Traefik 
sasl and security

---------------------------

"keeperOnCluster": ""

{
  "connector.class": "io.confluent.connect.jdbc.JdbcSinkConnector",
  "tasks.max": "1",
  "topics": "orders",
  "value.converter": "io.confluent.connect.avro.AvroConverter",
  "value.converter.schema.registry.url": "http://schema-registry:8081",
  "value.converter.enhanced.avro.schema.support": true,
  "key.converter": "org.apache.kafka.connect.storage.StringConverter",
  "connection.url": "jdbc:mysql://mysql:3306/test_db",
  "connection.user": "mysql",
  "connection.password": "mysql",
  "transforms": "unwrap",
  "transforms.unwrap.type": "io.debezium.transforms.ExtractNewRecordState",
  "transforms.unwrap.drop.tombstones": "false",

  "table.name.format": "orders",
  "pk.mode": "record_value",
  "pk.fields": "id",
  "insert.mode": "upsert",
 
  "auto.create": "true",
  "errors.tolerance": "all",
  "errors.log.enable": "true",
  "errors.log.include.messages": "true"
}

